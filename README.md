# AoE2 Behavioral Cloning

Treinamento de agentes para **Age of Empires II: Definitive Edition (AoE2DE)** usando **Behavioral Cloning (BC)** a partir de replays (`.aoe2record`).  
O objetivo Ã© aprender polÃ­ticas de alto nÃ­vel (macro) a partir de partidas humanas em campanhas, evitando o nÃ­vel de micro (cliques/tiles).

---

## ğŸš€ VisÃ£o geral

1. **Coletar dados**: extrair episÃ³dios de decisÃµes a partir de replays `.aoe2record`.  
2. **PrÃ©-processar**: reconstruir estados, mapear comandos para aÃ§Ãµes discretas, aplicar mÃ¡scara de aÃ§Ãµes vÃ¡lidas.  
3. **Treinar modelo supervisionado**: polÃ­tica Ï€Î¸(a|s) com *cross-entropy* mascarada.  
4. **Validar**: medir acurÃ¡cia top-k, taxa de aÃ§Ãµes invÃ¡lidas, mÃ©tricas especÃ­ficas de campanha (tempo atÃ© Feudal, composiÃ§Ã£o de exÃ©rcito, etc.).  
5. **InferÃªncia**: usar a polÃ­tica treinada em rollouts offline ou embutida num simulador.

---

## ğŸ“‚ Estrutura de pastas
```
aoe2-bc/
  data/
    replays/                 # arquivos .aoe2record
    episodes/                # episÃ³dios prÃ©-processados (*.jsonl)
  src/
    parsers/ao2record_parser.py
    data/dataset.py
    models/policy.py
    utils/action_space.py
    utils/mask.py
  preprocess.py
  train_bc.py
  rollout_offline.py
  README.md
```

---

## âš™ï¸ PrÃ©-processamento

```bash
python preprocess.py   --in data/replays   --out data/episodes   --action-space v1   --drop-bad
```

SaÃ­da: `*.jsonl` contendo episÃ³dios com:
- `state`: recursos, populaÃ§Ã£o, techs, edifÃ­cios, tempo, etc.  
- `action_id`: Ã­ndice discreto da aÃ§Ã£o executada.  
- `valid_action_mask`: quais aÃ§Ãµes eram possÃ­veis naquele estado.  

---

## ğŸ§  Treinamento

```bash
python train_bc.py   --train data/episodes/train.jsonl   --val data/episodes/val.jsonl   --n-actions 128
```

Modelo: MLP ou Transformer pequeno, com mÃ¡scara de aÃ§Ãµes aplicada em treino e inferÃªncia.  
Perda: *CrossEntropy* mascarada.  
MÃ©tricas:  
- **Acc@1**  
- **Acc@k** (k=3/5)  
- **Invalid-rate** (aÃ§Ãµes previstas mas invÃ¡lidas)  

---

## ğŸ® Rollout Offline

```bash
python rollout_offline.py   --policy checkpoints/best.pt   --episodes data/episodes/val.jsonl
```

Permite avaliar se a polÃ­tica reproduz build orders e timings prÃ³ximos aos humanos.  

---

## ğŸ› ï¸ EspaÃ§o de aÃ§Ãµes (v1)

- **Eco**: `Train(Villager)`, `Build(Farm)`, `Send(Vilsâ†’Wood)`, `AdvanceAge(Feudal)`, etc.  
- **Militar/Tech**: `Train(Militia)`, `Research(ManAtArms)`, `AttackMove(Sector3)` â€¦  
- **Objetivos campanha**: `Capture(Relic)`, `Destroy(TargetTowerWest)` â€¦  

PosiÃ§Ãµes sÃ£o discretizadas em *setores* (ex.: grade 3Ã—3).  

---

## ğŸ“Š Roadmap

- [x] Parser `.aoe2record` para JSONL de episÃ³dios  
- [x] Dataset + mÃ¡scara de aÃ§Ãµes vÃ¡lidas  
- [x] MLP Policy com PyTorch  
- [ ] Transformer Policy (contexto build order)  
- [ ] CLI de rollouts e mÃ©tricas por campanha  
- [ ] Suporte a *action head* fatorada (verbo + argumento)  
- [ ] DAgger offline (agregar divergÃªncias)  

---

## ğŸ”— ReferÃªncias
- [aoe2record](https://github.com/happyleavesaoc/aoe2record)  
- [AoE2ScenarioParser](https://github.com/KSneijders/AoE2ScenarioParser)  
- SethBlingâ€™s [MarI/O](https://www.youtube.com/watch?v=qv6UVOQ0F44) (inspiraÃ§Ã£o de imitation learning)  
